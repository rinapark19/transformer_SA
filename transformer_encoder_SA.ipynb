{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wFHFH1mXEM0NN96FR3KYP-95HGL_4h30","authorship_tag":"ABX9TyMxdgFqp1l2tbZAVswSvVJe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"SyzzYvjovTwy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688958571310,"user_tz":-540,"elapsed":4891,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"545e0f77-a286-4ba0-fbaf-b49ee77f1906"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, embedding_dim, num_heads = 8):\n","    super(MultiHeadAttention, self).__init__()\n","    self.embedding_dim = embedding_dim\n","    self.num_heads = num_heads\n","\n","    assert embedding_dim % self.num_heads == 0\n","\n","    self.projection_dim = embedding_dim // num_heads\n","    self.query_dense = nn.Linear(embedding_dim, embedding_dim)\n","    self.key_dense = nn.Linear(embedding_dim, embedding_dim)\n","    self.value_dense = nn.Linear(embedding_dim, embedding_dim)\n","    self.dense = nn.Linear(embedding_dim, embedding_dim)\n","\n","  def scaled_dot_product_attention(self, query, key, value):\n","    matmul_qk = torch.matmul(query, key.transpose(-2, -1))\n","    depth = torch.tensor(key.shape[-1], dtype=torch.float32)\n","    logits = matmul_qk / torch.sqrt(depth)\n","    attention_weights = F.softmax(logits, dim=-1)\n","    output = torch.matmul(attention_weights, value)\n","    return output, attention_weights\n","\n","  def split_heads(self, x, batch_size):\n","    x = x.view(batch_size, -1, self.num_heads, self.projection_dim)\n","    return x.transpose(1, 2)\n","\n","  def forward(self, inputs):\n","    batch_size = inputs.size(0)\n","    query = self.query_dense(inputs)\n","    key = self.key_dense(inputs)\n","    value = self.value_dense(inputs)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","    scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n","    scaled_attention = scaled_attention.transpose(1, 2)\n","    concat_attention = scaled_attention.reshape(batch_size, -1, self.embedding_dim)\n","    outputs = self.dense(concat_attention)\n","    return outputs"],"metadata":{"id":"s7GwK3aKvkf5","executionInfo":{"status":"ok","timestamp":1688967233166,"user_tz":-540,"elapsed":319,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","  def __init__(self, embedding_dim, num_heads, dff, rate = 0.1):\n","    super(TransformerBlock, self).__init__()\n","    self.att = MultiHeadAttention(embedding_dim, num_heads)\n","    self.ffn = nn.Sequential(\n","        nn.Linear(embedding_dim, dff),\n","        nn.ReLU(),\n","        nn.Linear(dff, embedding_dim)\n","    )\n","    self.layernorm1 = nn.LayerNorm(embedding_dim, eps = 1e-6)\n","    self.layernorm2 = nn.LayerNorm(embedding_dim, eps = 1e-6)\n","    self.dropout1 = nn.Dropout(rate)\n","    self.dropout2 = nn.Dropout(rate)\n","\n","  def forward(self, inputs):\n","    attn_output = self.att(inputs)\n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(inputs + attn_output)\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output)\n","    return self.layernorm2(out1 + ffn_output)"],"metadata":{"id":"iTuAJKhm8C2-","executionInfo":{"status":"ok","timestamp":1688967234885,"user_tz":-540,"elapsed":359,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class TokenAndPositionEmbedding(nn.Module):\n","  def __init__(self, max_len, vocab_size, embedding_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.token_emb = nn.Embedding(vocab_size, embedding_dim)\n","    self.pos_emb = nn.Embedding(max_len, embedding_dim)\n","\n","  def forward(self, x):\n","    positions = torch.arange(0, x.size(1), dtype=torch.long).unsqueeze(0).to(x.device)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    return x + positions"],"metadata":{"id":"SunocgEn8tuu","executionInfo":{"status":"ok","timestamp":1688967236889,"user_tz":-540,"elapsed":511,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","train = pd.read_csv(\"/content/drive/MyDrive/랩인턴/sentimental_analysis/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/랩인턴/sentimental_analysis/test (1).csv\")\n","\n","train_new_row = train.columns\n","test_new_row = test.columns\n","\n","train.columns = ['y_1', 'y_2', 'x']\n","train = train.append(pd.Series(), ignore_index=True)\n","train.loc[0] = train_new_row\n","\n","test.columns = ['y_1', 'y_2', 'x']\n","test = test.append(pd.Series(), ignore_index=True)\n","test.loc[0] = test_new_row\n","\n","train.dropna(inplace = True)\n","test.dropna(inplace= True)\n","\n","train.reset_index(drop=True)\n","test.reset_index(drop=True)\n","\n","X_train = list(train['x'])\n","y_train = list(train['y_1'])\n","\n","X_test = list(test['x'])\n","y_test = list(test['y_1'])\n","\n","y_train[0] = 1\n","y_test[0] = 0"],"metadata":{"id":"nxBdYSql9GRt","executionInfo":{"status":"ok","timestamp":1688967239250,"user_tz":-540,"elapsed":1242,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f6a3b2c-cd8d-448c-e3b9-2b939557ec5c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-20-46016a711b11>:10: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  train = train.append(pd.Series(), ignore_index=True)\n","<ipython-input-20-46016a711b11>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  train = train.append(pd.Series(), ignore_index=True)\n","<ipython-input-20-46016a711b11>:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  test = test.append(pd.Series(), ignore_index=True)\n","<ipython-input-20-46016a711b11>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  test = test.append(pd.Series(), ignore_index=True)\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","from transformers import BertTokenizer\n","\n","max_len = 512\n","vocab_size = 22000\n","\n","tokenizer = BertTokenizer(vocab_file = \"/content/drive/MyDrive/랩인턴/translator1/wiki-vocab.txt\", max_length = max_len)"],"metadata":{"id":"k_wk5TEYAgYf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688967247035,"user_tz":-540,"elapsed":6654,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"3de50b97-6701-4a50-c2fc-f893f7d46a6a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}]},{"cell_type":"code","source":["#@title 기본 제목 텍스트\n","pad_token_id = tokenizer.pad_token_id\n","\n","train_x = []\n","test_x = []\n","\n","for x in X_train:\n","  x = tokenizer.encode(x, max_length  = max_len, truncation=True)\n","  rest = max_len - len(x)\n","  x = torch.tensor(x + [pad_token_id] * rest)\n","  train_x.append(x)\n","\n","for x in X_test:\n","  x = tokenizer.encode(x, max_length= max_len, truncation=True)\n","  rest = max_len - len(x)\n","  x = torch.tensor(x + [pad_token_id] * rest)\n","  test_x.append(x)"],"metadata":{"id":"_VwuMsSPC8z-","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class CustomDataset(Dataset):\n","  def __init__(self, data, targets, tokenizer):\n","    self.data =data\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    text = self.data[idx]\n","    tokens = self.tokenizer.encode(text, add_special_tokens=True)\n","    label = 1 if self.targets[idx] == 1.0 else 0\n","    return torch.tensor(tokens), torch.tensor(label)\n","\n","def collate_fn(batch):\n","  inputs, targets = zip(*batch)\n","  inputs = pad_sequence(inputs, padding_value=0, batch_first=True)\n","  targets = torch.stack(targets, dim=0)\n","  return inputs, targets"],"metadata":{"id":"5_TXwfHqF-jS","executionInfo":{"status":"ok","timestamp":1688967247037,"user_tz":-540,"elapsed":23,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train_dataset = CustomDataset(X_train, y_train, tokenizer)\n","test_dataset = CustomDataset(X_test, y_test, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn = collate_fn)"],"metadata":{"id":"ZogTTJeZGeEb","executionInfo":{"status":"ok","timestamp":1688967247038,"user_tz":-540,"elapsed":16,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 32\n","num_heads = 2\n","dff = 32\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class MyModel(nn.Module):\n","  def __init__(self, max_len, vocab_size, embedding_dim, num_heads, dff):\n","    super(MyModel, self).__init__()\n","    self.embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n","    self.transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n","    self.dropout1 = nn.Dropout(0.1)\n","    self.linear1 = nn.Linear(embedding_dim, 20)\n","    self.dropout2 = nn.Dropout(0.1)\n","    self.linear2 = nn.Linear(20, 2)\n","\n","  def forward(self, inputs):\n","    x = self.embedding_layer(inputs)\n","    x = self.transformer_block(x)\n","    x = torch.mean(x, dim=1)\n","    x = x.squeeze(-1)\n","    x = self.dropout1(x)\n","    x = self.linear1(x)\n","    x = self.dropout2(x)\n","    x = self.linear2(x)\n","    return F.log_softmax(x, dim=-1)\n","\n","model = MyModel(max_len, vocab_size, embedding_dim, num_heads, dff).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(2):\n","  model.train()\n","  total_loss = 0.0\n","  total_samples = 0\n","  print(\"epoch: \", epoch)\n","  for inputs, targets in train_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    optimizer.zero_grad()\n","    output = model(inputs)\n","\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.item() * len(inputs)\n","    total_samples += len(inputs)\n","  epoch_loss = total_loss / total_samples\n","  print(\"Epoch %d, Training Loss: %.4f\" %(epoch + 1, epoch_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcCUyXwcDay6","executionInfo":{"status":"ok","timestamp":1688959307217,"user_tz":-540,"elapsed":594653,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"da5ef435-d1ba-4680-da8b-27d7f6211437"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:  0\n","Epoch 1, Training Loss: 0.5812\n","epoch:  1\n","Epoch 2, Training Loss: 0.5615\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","  correct = 0\n","  total = 0\n","  for inputs, targets in test_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    output = model(inputs)\n","    _, predicted = torch.max(output, dim=1)\n","    total += targets.size(0)\n","    correct += (predicted == targets).sum().item()\n","\n","accuracy = correct / total\n","print(\"테스트 정확도: %.4f\" % accuracy)"],"metadata":{"id":"7C6b7brZLJpg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688959334488,"user_tz":-540,"elapsed":2613,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"b3770e13-23e8-4a39-a036-62a8be79497d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 정확도: 0.7022\n"]}]},{"cell_type":"code","source":["def predict_sentiment(text):\n","  # token_ids = tokenizer(text)\n","  # token_ids = tokenizer.convert_tokens_to_ids(token_ids)\n","  # token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n","\n","  token_ids = tokenizer.encode(text)\n","  token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n","  token_ids = pad_sequence(token_ids, padding_value=0, batch_first=True)\n","\n","  with torch.no_grad():\n","    output = model(token_ids)\n","    _, preds = torch.max(output, dim=1)\n","\n","    print(preds)\n","\n","  if preds.item() == 1:\n","    print(\"긍정 리뷰입니다.\")\n","  else:\n","    print(\"부정 리뷰입니다.\")"],"metadata":{"id":"bC6lkdNvU_fI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_sentiment(\"너무 좋아요 ㅎㅎ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"geN2kHv1Wqvk","executionInfo":{"status":"ok","timestamp":1688937396841,"user_tz":-540,"elapsed":2,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"ebf6b9fc-c787-4024-9121-d7a2268b63f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1], device='cuda:0')\n","긍정 리뷰입니다.\n"]}]},{"cell_type":"code","source":["X_test[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CrVxIfGCXMGF","executionInfo":{"status":"ok","timestamp":1688935267128,"user_tz":-540,"elapsed":4,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"360eaa22-10bc-4b4d-c4a7-368a7181c796"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'제품도 빨리 배송해주시고 꼼꼼하게 잘챙겨주셨어요'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["*2*. Multi class classification"],"metadata":{"id":"4qe9995FkvB3"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class CustomDataset(Dataset):\n","  def __init__(self, data, targets, tokenizer):\n","    self.data =data\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    text = self.data[idx]\n","    tokens = self.tokenizer.encode(text, add_special_tokens=True)\n","    label = torch.tensor(self.targets[idx], dtype=torch.long)\n","    return torch.tensor(tokens), label\n","\n","def collate_fn(batch):\n","  inputs, targets = zip(*batch)\n","  inputs = pad_sequence(inputs, padding_value=0, batch_first=True)\n","  targets = torch.stack(targets, dim=0)\n","  return inputs, targets"],"metadata":{"id":"ib2DBXDSkxYm","executionInfo":{"status":"ok","timestamp":1688967250142,"user_tz":-540,"elapsed":357,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["X_train = list(train['x'])\n","y_train = list(train['y_2'])\n","\n","X_test = list(test['x'])\n","y_test = list(test['y_2'])\n","\n","y_train[0] = 5\n","y_test[0] = 2"],"metadata":{"id":"S2CDZjbPlV6-","executionInfo":{"status":"ok","timestamp":1688967252029,"user_tz":-540,"elapsed":317,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["for i in range(len(y_train)):\n","  y = y_train[i]\n","  y_train[i] = y -1\n","\n","for i in range(len(y_test)):\n","  y = y_test[i]\n","  y_test[i] = y - 1"],"metadata":{"id":"1UF6ltNKV6ca","executionInfo":{"status":"ok","timestamp":1688968244613,"user_tz":-540,"elapsed":431,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"hOmqEjXAWIGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CustomDataset(X_train, y_train, tokenizer)\n","test_dataset = CustomDataset(X_test, y_test, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn = collate_fn)"],"metadata":{"id":"5r5Jt0RDk3rQ","executionInfo":{"status":"ok","timestamp":1688967252961,"user_tz":-540,"elapsed":3,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 32\n","num_heads = 2\n","dff = 32\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class MyModel(nn.Module):\n","  def __init__(self, max_len, vocab_size, embedding_dim, num_heads, dff):\n","    super(MyModel, self).__init__()\n","    self.embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n","    self.transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n","    self.dropout1 = nn.Dropout(0.1)\n","    self.linear1 = nn.Linear(embedding_dim, 20)\n","    self.dropout2 = nn.Dropout(0.1)\n","    self.linear2 = nn.Linear(20, 5)\n","\n","  def forward(self, inputs):\n","    x = self.embedding_layer(inputs)\n","    x = self.transformer_block(x)\n","    x = torch.mean(x, dim=1)\n","    x = x.squeeze(-1)\n","    x = self.dropout1(x)\n","    x = self.linear1(x)\n","    x = self.dropout2(x)\n","    x = self.linear2(x)\n","    return F.log_softmax(x, dim=-1)\n","\n","model = MyModel(max_len, vocab_size, embedding_dim, num_heads, dff).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(2):\n","  model.train()\n","  total_loss = 0.0\n","  total_samples = 0\n","  print(\"epoch: \", epoch)\n","  for inputs, targets in train_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    optimizer.zero_grad()\n","    output = model(inputs)\n","\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.item() * len(inputs)\n","    total_samples += len(inputs)\n","  epoch_loss = total_loss / total_samples\n","  print(\"Epoch %d, Training Loss: %.4f\" %(epoch + 1, epoch_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlGAmQLllEuF","executionInfo":{"status":"ok","timestamp":1688969025383,"user_tz":-540,"elapsed":774950,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"2e2632b6-d6c4-4130-aa57-1be73b0bda9c"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:  0\n","Epoch 1, Training Loss: 1.1491\n","epoch:  1\n","Epoch 2, Training Loss: 1.1241\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def calculate_rmse(predictions, targets):\n","  mse = np.mean((predictions - targets) ** 2)\n","  rmse = np.sqrt(mse)\n","  return rmse\n","\n","predictions = []\n","targets_list = []\n","\n","model.eval()\n","with torch.no_grad():\n","  for inputs, targets in test_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    output = model(inputs)\n","    _, predicted = torch.max(output, dim=1)\n","    predictions.extend(predicted.cpu().numpy())\n","    targets_list.extend(targets.cpu().numpy())\n","\n","predictions = np.array(predictions)\n","targets = np.array(targets_list)\n","rmse = calculate_rmse(predictions, targets)\n","\n","print(\"RMSE: \", rmse)"],"metadata":{"id":"r1-Kpc5_lME0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688969543394,"user_tz":-540,"elapsed":4568,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"c3da03ff-80ca-4cb6-b3d0-1fc7ffe6d955"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE:  1.8568295394694192\n"]}]},{"cell_type":"code","source":["def predict_score(text):\n","  token_ids = tokenizer.encode(text)\n","  token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n","  token_ids = pad_sequence(token_ids, padding_value=0, batch_first=True)\n","\n","  with torch.no_grad():\n","    output = model(token_ids)\n","    predicted_class = torch.argmax(output, dim=1)\n","    predicted_score = predicted_class.item() + 1\n","  return predicted_score"],"metadata":{"id":"7MAqwWNOblh8","executionInfo":{"status":"ok","timestamp":1688969774971,"user_tz":-540,"elapsed":281,"user":{"displayName":"박채린","userId":"04948549455345468544"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["predict_score(\"별로예요\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIaBFJJrcXJX","executionInfo":{"status":"ok","timestamp":1688969793675,"user_tz":-540,"elapsed":309,"user":{"displayName":"박채린","userId":"04948549455345468544"}},"outputId":"b379c409-a39e-4092-ad53-f4f4dc87c2f5"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":45}]}]}